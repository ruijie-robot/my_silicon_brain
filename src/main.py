#!/usr/bin/env python3
"""
å‡½æ•°å¼ç¼–ç¨‹ç‰ˆæœ¬çš„æŠ•èµ„ç ”ç©¶æ”¯æŒç³»ç»Ÿæ¼”ç¤ºè„šæœ¬
ä½¿ç”¨çº¯å‡½æ•°å’Œå‡½æ•°ç»„åˆå®ç°
"""

import asyncio
import sys
from pathlib import Path
from typing import List, Tuple, Callable
from functools import partial

sys.path.append(str(Path(__file__).parent))

from knowledge_base import (
    create_kb_context,
    scan_and_add_directory,
    search_kb,
    load_file_hashes,
    save_file_hashes
)


# ============================================================================
# çº¯å‡½æ•° - æ ¼å¼åŒ–è¾“å‡º
# ============================================================================

def format_search_result(index: int, result, max_length: int = 100) -> str:
    """æ ¼å¼åŒ–æœç´¢ç»“æœ - çº¯å‡½æ•°"""
    text = result.text[:max_length] + "..." if len(result.text) > max_length else result.text
    return f"  {index}. {text} (ç›¸å…³åº¦: {result.score:.3f})"


def format_search_results(results: List, max_length: int = 100) -> List[str]:
    """æ ¼å¼åŒ–æœç´¢ç»“æœåˆ—è¡¨ - çº¯å‡½æ•°"""
    return [
        format_search_result(i, result, max_length)
        for i, result in enumerate(results, 1)
    ]


def format_header(title: str) -> str:
    """æ ¼å¼åŒ–æ ‡é¢˜ - çº¯å‡½æ•°"""
    return f"\n=== {title} ==="


def format_query(query: str) -> str:
    """æ ¼å¼åŒ–æŸ¥è¯¢ - çº¯å‡½æ•°"""
    return f"\næŸ¥è¯¢: {query}"


# ============================================================================
# æ¼”ç¤ºå‡½æ•° - çŸ¥è¯†åº“åŠŸèƒ½
# ============================================================================

async def demo_knowledge_base() -> None:
    """æ¼”ç¤ºçŸ¥è¯†åº“åŠŸèƒ½"""
    print(format_header("çŸ¥è¯†åº“åŠŸèƒ½æ¼”ç¤º"))

    # åˆ›å»ºçŸ¥è¯†åº“ä¸Šä¸‹æ–‡
    client, coll_config, llm_config, proc_config = create_kb_context(
        collection_name="finance_knowledge_HNSW_functional"
    )

    # åŠ è½½æ–‡ä»¶å“ˆå¸Œ
    file_hashes = load_file_hashes()

    # æ‰«ææ–‡æ¡£ç›®å½•
    documents_dir = "documents"
    if Path(documents_dir).exists():
        print(f"ğŸ“ æ‰«æç›®å½•: {documents_dir}")
        file_hashes = scan_and_add_directory(
            client,
            coll_config.collection_name,
            documents_dir,
            llm_config,
            proc_config,
            file_hashes
        )

        # ä¿å­˜å“ˆå¸Œ
        save_file_hashes(file_hashes)
    else:
        print(f"âš ï¸  ç›®å½• {documents_dir} ä¸å­˜åœ¨")

    # æµ‹è¯•æœç´¢
    print("\nğŸ” æµ‹è¯•çŸ¥è¯†åº“æœç´¢...")
    search_queries = [
        "ä»Šå¹´å›½åº†èŠ‚æ¶ˆè´¹æ€ä¹ˆæ ·ï¼Ÿ",
        "4æœˆå…³ç¨å¯¹ä¸­å›½è‚¡å¸‚çš„å†²å‡»?",
        "é»„é‡‘æœªæ¥èµ°åŠ¿ï¼Ÿ",
        "ç‰¹æ–¯æ‹‰æœªæ¥èµ°åŠ¿ï¼Ÿ"
    ]

    # åˆ›å»ºé¢„é…ç½®çš„æœç´¢å‡½æ•°
    search_fn = partial(
        search_kb,
        client=client,
        collection_name=coll_config.collection_name,
        llm_config=llm_config,
        limit=2
    )

    # æ‰§è¡Œæœç´¢å¹¶æ˜¾ç¤ºç»“æœ
    for query in search_queries:
        print(format_query(query))
        results = search_fn(query=query)
        formatted_results = format_search_results(results)

        for formatted_result in formatted_results:
            print(formatted_result)


# ============================================================================
# æ¼”ç¤ºå‡½æ•° - æœ¬åœ° LLM åŠŸèƒ½
# ============================================================================

async def demo_local_llm_direct() -> None:
    """æ¼”ç¤ºæœ¬åœ° LLM åŠŸèƒ½ï¼ˆç›´æ¥å‡½æ•°è°ƒç”¨æ–¹å¼ï¼‰"""
    print(format_header("æœ¬åœ°LLMåŠŸèƒ½æ¼”ç¤º (å‡½æ•°å¼)"))

    try:
        from local_llm_direct import (
            create_config,
            list_models,
            simple_chat,
            stream_chat,
            chat_with_history,
            create_user_message,
            create_system_message,
            create_assistant_message
        )

        # åˆ—å‡ºå¯ç”¨æ¨¡å‹
        models = list_models()
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {models}")

        if not models:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„Ollamaæ¨¡å‹")
            print("ğŸ’¡ è¯·å…ˆå®‰è£…æ¨¡å‹: ollama pull qwen2.5:latest")
            return

        # é€‰æ‹©æ¨¡å‹
        model_name = models[1] if len(models) > 1 else models[0]
        embed_model_name = models[0]
        print(f"\nğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}, åµŒå…¥æ¨¡å‹: {embed_model_name}")

        # åˆ›å»ºé…ç½®
        config = create_config(model=model_name, embed_model=embed_model_name)

        # æµ‹è¯•é—®é¢˜
        test_queries = [
            {
                "prompt": "ç®€è¿°ä¸­å›½è‚¡å¸‚çš„ä¸»è¦ç‰¹ç‚¹",
                "system": "ä½ æ˜¯ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆï¼Œè¯·ç”¨ç®€æ´çš„è¯­è¨€å›ç­”ã€‚"
            },
            {
                "prompt": "è§£é‡Šä»·å€¼æŠ•èµ„çš„æ ¸å¿ƒç†å¿µ",
                "system": "ä½ æ˜¯å·´è²ç‰¹çš„å­¦ç”Ÿï¼Œè¯·ä¼ æˆä»·å€¼æŠ•èµ„çš„ç²¾é«“ã€‚"
            },
            {
                "prompt": "æ–°èƒ½æºæ±½è½¦æ¿å—æœ‰å“ªäº›æŠ•èµ„æœºä¼šï¼Ÿ",
                "system": "ä½ æ˜¯æ–°èƒ½æºè¡Œä¸šä¸“å®¶ï¼Œè¯·åˆ†ææŠ•èµ„å‰æ™¯ã€‚"
            }
        ]

        # é€ä¸ªæµ‹è¯•
        for i, query_info in enumerate(test_queries, 1):
            print(f"\nğŸ“ é—®é¢˜ {i}: {query_info['prompt']}")
            print(f"ğŸ­ è§’è‰²: {query_info['system']}")

            result = simple_chat(
                config=config,
                prompt=query_info['prompt'],
                system_prompt=query_info['system']
            )

            if result.is_success:
                print(f"ğŸ’¬ å›ç­”: {result.content[:300]}...")
            else:
                print(f"âŒ é”™è¯¯: {result.error}")

            if i < len(test_queries):
                print("-" * 50)

        # æ¼”ç¤ºå¤šè½®å¯¹è¯
        print(f"\nğŸ”„ æ¼”ç¤ºå¤šè½®å¯¹è¯åŠŸèƒ½:")
        print("=" * 50)

        # æ„å»ºå¯¹è¯å†å²
        messages = [
            create_system_message('ä½ æ˜¯ä¸“ä¸šçš„è‚¡ç¥¨æŠ•èµ„é¡¾é—®'),
            create_user_message('æˆ‘æƒ³äº†è§£èŒ…å°è‚¡ç¥¨')
        ]

        print("ç”¨æˆ·: æˆ‘æƒ³äº†è§£èŒ…å°è‚¡ç¥¨")

        result1 = chat_with_history(config, messages)
        if result1.is_success:
            print(f"åŠ©æ‰‹: {result1.content[:200]}...")

            # æ·»åŠ å›å¤åˆ°å†å²
            messages.append(create_assistant_message(result1.content))
            messages.append(create_user_message('ç°åœ¨ä»·æ ¼åˆé€‚ä¹°å…¥å—ï¼Ÿ'))

            print("\nç”¨æˆ·: ç°åœ¨ä»·æ ¼åˆé€‚ä¹°å…¥å—ï¼Ÿ")

            result2 = chat_with_history(config, messages)
            if result2.is_success:
                print(f"åŠ©æ‰‹: {result2.content[:200]}...")
            else:
                print(f"âŒ é”™è¯¯: {result2.error}")
        else:
            print(f"âŒ é”™è¯¯: {result1.error}")

        # æ¼”ç¤ºæµå¼è¾“å‡º
        print(f"\nğŸŒŠ æ¼”ç¤ºæµå¼è¾“å‡º:")
        print("=" * 50)
        print("é—®é¢˜: åˆ†æä¸€ä¸‹æ¯”äºšè¿ªçš„æŠ•èµ„ä»·å€¼")
        print("å›ç­”: ", end="", flush=True)

        for chunk in stream_chat(
            config,
            "åˆ†æä¸€ä¸‹æ¯”äºšè¿ªçš„æŠ•èµ„ä»·å€¼ï¼ŒåŒ…æ‹¬æŠ€æœ¯ä¼˜åŠ¿å’Œå¸‚åœºå‰æ™¯"
        ):
            print(chunk, end="", flush=True)
        print()

    except ImportError:
        print("âŒ éœ€è¦å®‰è£…ollama-pythonåŒ…")
        print("ğŸ’¡ è¿è¡Œ: pip install ollama")
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ: ollama serve")


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

async def main() -> None:
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              æŠ•èµ„ç ”ç©¶æ”¯æŒç³»ç»Ÿæ¼”ç¤º (å‡½æ•°å¼ç‰ˆæœ¬)                 â•‘
â•‘           Investment Research System Demo (Functional)       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # æ¼”ç¤ºçŸ¥è¯†åº“åŠŸèƒ½
    try:
        await demo_knowledge_base()
    except Exception as e:
        print(f"âŒ çŸ¥è¯†åº“æ¼”ç¤ºå¤±è´¥: {e}")

    # æ¼”ç¤ºæœ¬åœ° LLM åŠŸèƒ½
    # try:
    #     await demo_local_llm_direct()
    # except Exception as e:
    #     print(f"âŒ æœ¬åœ°LLMæ¼”ç¤ºå¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())
